{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Python Libraries and Modules for Data Analysis\n",
        "\n",
        "This notebook utilizes a variety of Python libraries for data analysis and machine learning. Below is a summary of the imported libraries and their roles:\n",
        "\n",
        "\n",
        "1. **Data Manipulation and Loading**\n",
        "   - `pandas as pd`: Provides high-performance data structures and data analysis tools.\n",
        "   - `numpy as np`: Supports large, multi-dimensional arrays and matrices with mathematical functions.\n",
        "   - `scipy.io`: Contains functions for reading and writing data in MATLAB `.mat` file format.\n",
        "     - `loadmat`: Loads MATLAB `.mat` files.\n",
        "   - `h5py`: Reads and writes HDF5 files, including `.mat` files that use the HDF5 format.\n",
        "   - `glob`: Finds all pathnames matching a specified pattern, useful for file searching.\n",
        "   - `os`: Provides a way of using operating system-dependent functionality like reading or writing to the file system.\n",
        "   - `re`: Supports regular expressions for string manipulation.\n",
        "\n",
        "2. **Data Preprocessing and Feature Engineering**\n",
        "   - `scipy.signal`: Provides signal processing functions.\n",
        "     - `hilbert`: Computes the analytic signal using the Hilbert transform.\n",
        "     - `butter`: Designs a Butterworth filter.\n",
        "     - `filtfilt`: Applies a forward and backward filter to avoid phase distortion.\n",
        "     - `detrend`: Removes linear trend from data.\n",
        "\n",
        "4. **Randomization and Miscellaneous Utilities**\n",
        "   - `random`: Implements pseudo-random number generators for various distributions.\n",
        "\n",
        "These libraries and modules facilitate efficient data manipulation, preprocessing, model evaluation, and file handling throughout the analysis."
      ],
      "metadata": {
        "id": "CytPLvwsyOOo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kt8yNpDwllfY"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import joblib\n",
        "from scipy.io import loadmat\n",
        "import scipy.io as sio\n",
        "import random\n",
        "from scipy import signal\n",
        "from scipy.signal import hilbert, butter, filtfilt, detrend\n",
        "import h5py\n",
        "import glob\n",
        "import os\n",
        "import re\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### All relevant data files i.e. the raw MEG .mat files should be uploaded to google drive, imported and mounted into this notebook"
      ],
      "metadata": {
        "id": "XLVNhJKiyMp9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CCpPNcbX7H2O",
        "outputId": "8e05a8af-c9e9-4b9f-fbd5-91cc56712443"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "# Accessing and Inspecting .mat Files from Google Drive\n",
        "\n",
        "This section demonstrates how to access and inspect `.mat` files stored in Google Drive using the `h5py` library. The script will:\n",
        "\n",
        "1. Specify the path to the `.mat` file.\n",
        "2. Open the file using `h5py`.\n",
        "3. Print out the keys and details of datasets and groups contained in the file.\n",
        "\n"
      ],
      "metadata": {
        "id": "XIC303YRvunf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify the file path to the .mat file in Google Drive\n",
        "mat_file_path = '/content/drive/MyDrive/MEG DATA/LSD_DRU_subject_15.mat'\n",
        "\n",
        "# Open the .mat file in read mode using h5py, and ensure it closes automatically after the block\n",
        "with h5py.File(mat_file_path, 'r') as f:\n",
        "\n",
        "    # Print the keys (dataset and group names) present in the .mat file\n",
        "    print(\"Keys in the .mat file:\", list(f.keys()))\n",
        "\n",
        "    # Loop through each key in the .mat file to inspect its contents\n",
        "    for key in f.keys():\n",
        "        item = f[key]  # Retrieve the item associated with the current key\n",
        "\n",
        "        # Check if the item is a Group (a collection of datasets or sub-groups)\n",
        "        if isinstance(item, h5py.Group):\n",
        "            print(f\"Group {key}:\")  # Print the name of the group\n",
        "\n",
        "            # Loop through each key in the group to inspect subgroups or datasets\n",
        "            for subgroup_key in item.keys():\n",
        "                subgroup_item = item[subgroup_key]  # Retrieve the item in the subgroup\n",
        "                # Print details about the subgroup: its shape and data type\n",
        "                print(f\"  Subgroup {subgroup_key}: shape {subgroup_item.shape}, dtype {subgroup_item.dtype}\")\n",
        "\n",
        "        # If the item is a Dataset, print its shape and data type\n",
        "        elif isinstance(item, h5py.Dataset):\n",
        "            print(f\"Dataset {key}: shape {item.shape}, dtype {item.dtype}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2EqxWYY3tqS8",
        "outputId": "545e6cb7-b8a3-4d30-9ef8-99fcbc9495e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keys in the .mat file: ['#refs#', 'X', 'lnfilter']\n",
            "Group #refs#:\n",
            "  Subgroup a: shape (2,), dtype uint64\n",
            "Dataset X: shape (209, 1200, 90), dtype float64\n",
            "Group lnfilter:\n",
            "  Subgroup fdesc: shape (4, 1), dtype uint16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yHtQYOuPZf1c"
      },
      "source": [
        "### This cell outlines the comprehensive pipeline and steps involved in processing MEG data from a `.mat` file. The workflow includes defining regions of interest (ROIs), applying preprocessing techniques, and calculating the Lempel-Ziv (LZ) complexity for each ROI."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f86CLC-PyEu-",
        "outputId": "ece086d7-6b27-415c-b039-aa7d43adc54e",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keys in the .mat file: ['#refs#', 'X', 'lnfilter']\n",
            "Loaded data shape: (277, 1200, 90)\n",
            "Data shape for ROI 1: (277, 90)\n",
            "Data shape after downsampling for ROI 1: (277, 30)\n",
            "Data shape before filtering: (277, 30)\n",
            "Data shape after filtering: (277, 30)\n",
            "Data shape for ROI 2: (277, 90)\n",
            "Data shape after downsampling for ROI 2: (277, 30)\n",
            "Data shape before filtering: (277, 30)\n",
            "Data shape after filtering: (277, 30)\n",
            "Data shape for ROI 17: (277, 90)\n",
            "Data shape after downsampling for ROI 17: (277, 30)\n",
            "Data shape before filtering: (277, 30)\n",
            "Data shape after filtering: (277, 30)\n",
            "Data shape for ROI 3: (277, 90)\n",
            "Data shape after downsampling for ROI 3: (277, 30)\n",
            "Data shape before filtering: (277, 30)\n",
            "Data shape after filtering: (277, 30)\n",
            "Data shape for ROI 4: (277, 90)\n",
            "Data shape after downsampling for ROI 4: (277, 30)\n",
            "Data shape before filtering: (277, 30)\n",
            "Data shape after filtering: (277, 30)\n",
            "Data shape for ROI 5: (277, 90)\n",
            "Data shape after downsampling for ROI 5: (277, 30)\n",
            "Data shape before filtering: (277, 30)\n",
            "Data shape after filtering: (277, 30)\n",
            "Data shape for ROI 29: (277, 90)\n",
            "Data shape after downsampling for ROI 29: (277, 30)\n",
            "Data shape before filtering: (277, 30)\n",
            "Data shape after filtering: (277, 30)\n",
            "Data shape for ROI 30: (277, 90)\n",
            "Data shape after downsampling for ROI 30: (277, 30)\n",
            "Data shape before filtering: (277, 30)\n",
            "Data shape after filtering: (277, 30)\n",
            "Data shape for ROI 79: (277, 90)\n",
            "Data shape after downsampling for ROI 79: (277, 30)\n",
            "Data shape before filtering: (277, 30)\n",
            "Data shape after filtering: (277, 30)\n",
            "Data shape for ROI 31: (277, 90)\n",
            "Data shape after downsampling for ROI 31: (277, 30)\n",
            "Data shape before filtering: (277, 30)\n",
            "Data shape after filtering: (277, 30)\n",
            "Data shape for ROI 32: (277, 90)\n",
            "Data shape after downsampling for ROI 32: (277, 30)\n",
            "Data shape before filtering: (277, 30)\n",
            "Data shape after filtering: (277, 30)\n",
            "Data shape for ROI 33: (277, 90)\n",
            "Data shape after downsampling for ROI 33: (277, 30)\n",
            "Data shape before filtering: (277, 30)\n",
            "Data shape after filtering: (277, 30)\n",
            "Data shape for ROI 37: (277, 90)\n",
            "Data shape after downsampling for ROI 37: (277, 30)\n",
            "Data shape before filtering: (277, 30)\n",
            "Data shape after filtering: (277, 30)\n",
            "Data shape for ROI 38: (277, 90)\n",
            "Data shape after downsampling for ROI 38: (277, 30)\n",
            "Data shape before filtering: (277, 30)\n",
            "Data shape after filtering: (277, 30)\n",
            "Data shape for ROI 39: (277, 90)\n",
            "Data shape after downsampling for ROI 39: (277, 30)\n",
            "Data shape before filtering: (277, 30)\n",
            "Data shape after filtering: (277, 30)\n",
            "Data shape for ROI 43: (277, 90)\n",
            "Data shape after downsampling for ROI 43: (277, 30)\n",
            "Data shape before filtering: (277, 30)\n",
            "Data shape after filtering: (277, 30)\n",
            "Data shape for ROI 44: (277, 90)\n",
            "Data shape after downsampling for ROI 44: (277, 30)\n",
            "Data shape before filtering: (277, 30)\n",
            "Data shape after filtering: (277, 30)\n",
            "Data shape for ROI 45: (277, 90)\n",
            "Data shape after downsampling for ROI 45: (277, 30)\n",
            "Data shape before filtering: (277, 30)\n",
            "Data shape after filtering: (277, 30)\n",
            "Data shape for ROI 59: (277, 90)\n",
            "Data shape after downsampling for ROI 59: (277, 30)\n",
            "Data shape before filtering: (277, 30)\n",
            "Data shape after filtering: (277, 30)\n",
            "Data shape for ROI 60: (277, 90)\n",
            "Data shape after downsampling for ROI 60: (277, 30)\n",
            "Data shape before filtering: (277, 30)\n",
            "Data shape after filtering: (277, 30)\n",
            "Data shape for ROI 61: (277, 90)\n",
            "Data shape after downsampling for ROI 61: (277, 30)\n",
            "Data shape before filtering: (277, 30)\n",
            "Data shape after filtering: (277, 30)\n",
            "Data shape for ROI 71: (277, 90)\n",
            "Data shape after downsampling for ROI 71: (277, 30)\n",
            "Data shape before filtering: (277, 30)\n",
            "Data shape after filtering: (277, 30)\n",
            "Data shape for ROI 72: (277, 90)\n",
            "Data shape after downsampling for ROI 72: (277, 30)\n",
            "Data shape before filtering: (277, 30)\n",
            "Data shape after filtering: (277, 30)\n",
            "Data shape for ROI 73: (277, 90)\n",
            "Data shape after downsampling for ROI 73: (277, 30)\n",
            "Data shape before filtering: (277, 30)\n",
            "Data shape after filtering: (277, 30)\n",
            "Channel: 1, ROI: sensorimotor, LZ Complexity: 0.8154121863799283\n",
            "Channel: 2, ROI: sensorimotor, LZ Complexity: 0.8032345013477089\n",
            "Channel: 17, ROI: sensorimotor, LZ Complexity: 0.7847533632286996\n",
            "Channel: 3, ROI: frontal, LZ Complexity: 0.813953488372093\n",
            "Channel: 4, ROI: frontal, LZ Complexity: 0.7944344703770198\n",
            "Channel: 5, ROI: frontal, LZ Complexity: 0.8315412186379928\n",
            "Channel: 29, ROI: temporal, LZ Complexity: 0.7732974910394266\n",
            "Channel: 30, ROI: temporal, LZ Complexity: 0.8244824482448245\n",
            "Channel: 79, ROI: temporal, LZ Complexity: 0.8375224416517055\n",
            "Channel: 31, ROI: cingulate, LZ Complexity: 0.810126582278481\n",
            "Channel: 32, ROI: cingulate, LZ Complexity: 0.7886690647482014\n",
            "Channel: 33, ROI: cingulate, LZ Complexity: 0.9030520646319569\n",
            "Channel: 37, ROI: limbic, LZ Complexity: 0.8184357541899442\n",
            "Channel: 38, ROI: limbic, LZ Complexity: 0.8483720930232558\n",
            "Channel: 39, ROI: limbic, LZ Complexity: 0.7588717015468608\n",
            "Channel: 43, ROI: occipital, LZ Complexity: 0.8389982110912343\n",
            "Channel: 44, ROI: occipital, LZ Complexity: 0.8791405550581916\n",
            "Channel: 45, ROI: occipital, LZ Complexity: 0.8584310189359784\n",
            "Channel: 59, ROI: parietal, LZ Complexity: 0.7113309352517986\n",
            "Channel: 60, ROI: parietal, LZ Complexity: 0.8143497757847533\n",
            "Channel: 61, ROI: parietal, LZ Complexity: 0.8847549909255898\n",
            "Channel: 71, ROI: subcortical, LZ Complexity: 0.8583180987202925\n",
            "Channel: 72, ROI: subcortical, LZ Complexity: 0.853393665158371\n",
            "Channel: 73, ROI: subcortical, LZ Complexity: 0.8377153218495014\n"
          ]
        }
      ],
      "source": [
        "# Define ROIs and their corresponding regions\n",
        "roi_regions = {\n",
        "    'sensorimotor': [1, 2, 17, 18, 57, 58],\n",
        "    'frontal': [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28],\n",
        "    'temporal': [29, 30, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90],\n",
        "    'cingulate': [31, 32, 33, 34, 35, 36],\n",
        "    'limbic': [37, 38, 39, 40, 41, 42],\n",
        "    'occipital': [43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56],\n",
        "    'parietal': [59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70],\n",
        "    'subcortical': [71, 72, 73, 74, 75, 76, 77, 78]\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "def select_fixed_rois(roi_regions, num_samples_per_region=3):\n",
        "\n",
        "      \"\"\"\n",
        "    Selects a fixed number of Regions of Interest (ROIs) from each specified brain region.\n",
        "\n",
        "    Parameters:\n",
        "    roi_regions (dict): A dictionary where keys are brain region names, and values are lists of ROIs in those regions.\n",
        "    num_samples_per_region (int): The number of ROIs to select from each brain region.\n",
        "\n",
        "    Returns:\n",
        "    selected_rois (list): A list of selected ROIs.\n",
        "    roi_names (list): A list of region names corresponding to the selected ROIs.\n",
        "    \"\"\"\n",
        "    selected_rois = []\n",
        "    roi_names = []\n",
        "    for region, rois in roi_regions.items():\n",
        "        selected_rois.extend(rois[:num_samples_per_region])\n",
        "        roi_names.extend([region] * num_samples_per_region)\n",
        "    return selected_rois, roi_names\n",
        "\n",
        "def apply_bandpass_filter(data, low_cutoff, high_cutoff, fs):\n",
        "\n",
        "  \"\"\"\n",
        "    Applies a bandpass filter to the input data.\n",
        "\n",
        "    Parameters:\n",
        "    data (np.array): The input signal data to be filtered (2D array with shape [samples, channels]).\n",
        "    low_cutoff (float): The low frequency cutoff for the bandpass filter.\n",
        "    high_cutoff (float): The high frequency cutoff for the bandpass filter.\n",
        "    fs (float): The sampling frequency of the data.\n",
        "\n",
        "    Returns:\n",
        "    filtered_data (np.array): The filtered data with the same shape as the input data.\n",
        "    \"\"\"\n",
        "    print(\"Data shape before filtering:\", data.shape)\n",
        "    nyq = 0.5 * fs\n",
        "    low = low_cutoff / nyq\n",
        "    high = high_cutoff / nyq\n",
        "    b, a = butter(4, [low, high], btype='band')\n",
        "    filtered_data = np.zeros_like(data)\n",
        "    for i in range(data.shape[1]):\n",
        "        filtered_data[:, i] = filtfilt(b, a, data[:, i])\n",
        "    print(\"Data shape after filtering:\", filtered_data.shape)\n",
        "    return filtered_data\n",
        "\n",
        "def Pre(X):\n",
        "\n",
        "   \"\"\"\n",
        "    Preprocesses the input data by detrending and centering it around zero.\n",
        "\n",
        "    Parameters:\n",
        "    X (np.array): The input data to preprocess (2D array with shape [epochs, channels]).\n",
        "\n",
        "    Returns:\n",
        "    Z (np.array): The preprocessed data with the same shape as the input.\n",
        "    \"\"\"\n",
        "    epochs, ro = X.shape\n",
        "    Z = np.zeros((epochs, ro))\n",
        "    for e in range(epochs):\n",
        "        Z[e, :] = detrend(X[e, :] - np.mean(X[e, :]), axis=0)\n",
        "    return Z\n",
        "\n",
        "def cpr(string):\n",
        "\n",
        "  \"\"\"\n",
        "    Calculates the Lempel-Ziv complexity of a binary string.\n",
        "\n",
        "    Parameters:\n",
        "    string (str): The input binary string.\n",
        "\n",
        "    Returns:\n",
        "    int: The Lempel-Ziv complexity, which is the length of the dictionary built from the string.\n",
        "    \"\"\"\n",
        "    d = {}\n",
        "    w = ''\n",
        "    for c in string:\n",
        "        wc = w + c\n",
        "        if wc in d:\n",
        "            w = wc\n",
        "        else:\n",
        "            d[wc] = wc\n",
        "            w = c\n",
        "    return len(d)\n",
        "\n",
        "def str_col(X):\n",
        "\n",
        "   \"\"\"\n",
        "    Converts the input signal data into a binary string based on amplitude thresholds.\n",
        "\n",
        "    Parameters:\n",
        "    X (np.array): The input signal data (2D array with shape [epochs, channels]).\n",
        "\n",
        "    Returns:\n",
        "    str: A binary string representation of the input data.\n",
        "    \"\"\"\n",
        "    epochs, ro = X.shape\n",
        "    TH = np.zeros(epochs)\n",
        "    M = np.zeros((epochs, ro))\n",
        "    for e in range(epochs):\n",
        "        M[e, :] = np.abs(hilbert(X[e, :]))\n",
        "        TH[e] = np.mean(M[e, :])\n",
        "\n",
        "    s = ''\n",
        "    for e in range(epochs):\n",
        "        for i in range(ro):\n",
        "            if M[e, i] > TH[e]:\n",
        "                s += '1'\n",
        "            else:\n",
        "                s += '0'\n",
        "    return s\n",
        "\n",
        "def LZc(X):\n",
        "\n",
        "  \"\"\"\n",
        "    Computes the Lempel-Ziv complexity of preprocessed signal data.\n",
        "\n",
        "    Parameters:\n",
        "    X (np.array): The input signal data (2D array with shape [epochs, channels]).\n",
        "\n",
        "    Returns:\n",
        "    float: The normalized Lempel-Ziv complexity value.\n",
        "    \"\"\"\n",
        "    X = Pre(X)\n",
        "    SC = str_col(X)\n",
        "    M = list(SC)\n",
        "    random.shuffle(M)\n",
        "    w = ''\n",
        "    for i in range(len(M)):\n",
        "        w += M[i]\n",
        "    return cpr(SC) / float(cpr(w))\n",
        "\n",
        "def load_mat_file_h5py(mat_file_path):\n",
        "\n",
        "   \"\"\"\n",
        "    Loads data from a .mat file using the h5py library.\n",
        "\n",
        "    Parameters:\n",
        "    mat_file_path (str): The file path to the .mat file.\n",
        "\n",
        "    Returns:\n",
        "    np.array: The data extracted from the .mat file.\n",
        "    \"\"\"\n",
        "\n",
        "    with h5py.File(mat_file_path, 'r') as f:\n",
        "        print(\"Keys in the .mat file:\", list(f.keys()))\n",
        "        data = f['X'][:]\n",
        "        print(\"Loaded data shape:\", data.shape)\n",
        "        return data\n",
        "\n",
        "def process_file(mat_file_path):\n",
        "  \"\"\"\n",
        "    Processes a .mat file by loading data, sampling ROIs, and printing data shapes.\n",
        "\n",
        "    Parameters:\n",
        "    mat_file_path (str): The file path to the .mat file.\n",
        "\n",
        "    Steps:\n",
        "    - Load data from the .mat file.\n",
        "    - Select a fixed number of ROIs and their corresponding names.\n",
        "    - For each selected ROI, extract the relevant data and print its shape.\n",
        "    \"\"\"\n",
        "\n",
        "    # Load the data\n",
        "    data = load_mat_file_h5py(mat_file_path)\n",
        "\n",
        "    # Sample fixed ROIs and get their names\n",
        "    sampled_rois, roi_names = select_fixed_rois(roi_regions, num_samples_per_region=3)\n",
        "\n",
        "    results = []\n",
        "\n",
        "    for i, roi in enumerate(sampled_rois):\n",
        "        # Extract the data for the current ROI\n",
        "        selected_data = data[:, roi, :]\n",
        "        print(f\"Data shape for ROI {roi}: {selected_data.shape}\")\n",
        "\n",
        "        # Perform downsampling\n",
        "        decimation_factor = 3\n",
        "        downsampled_data = selected_data[:, ::decimation_factor]\n",
        "        print(f\"Data shape after downsampling for ROI {roi}: {downsampled_data.shape}\")\n",
        "\n",
        "        # Apply bandpass filter\n",
        "        filtered_data = apply_bandpass_filter(downsampled_data, low_cutoff=0.1, high_cutoff=30, fs=600)\n",
        "\n",
        "        # Compute LZ complexity\n",
        "        lz_complexity = LZc(filtered_data)\n",
        "\n",
        "        # Append the result\n",
        "        results.append((roi, roi_names[i], lz_complexity))\n",
        "\n",
        "    return results\n",
        "\n",
        "# Example usage for one file\n",
        "file_path = '/content/drive/MyDrive/MEG DATA/KET_DRU_subject_01.mat'\n",
        "lz_complexities = process_file(file_path)\n",
        "\n",
        "# Print results\n",
        "for roi, roi_name, lz_complexity in lz_complexities:\n",
        "    print(f'Channel: {roi}, ROI: {roi_name}, LZ Complexity: {lz_complexity}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RQ9oWg6J3ZeH"
      },
      "source": [
        "### Calculating Lempel Ziv for each subject file"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####This script handles and iterates through all 97 .mat files containing the raw MEG data, performs random sampling of ROIs, and processes each file to compute and average LZ complexity measures. Results are collected for all 3 psychedelics and conditions (drug/placebo), saved to a CSV file, and prepared for further analysis.                                                        NB: The computational load is substantial due to the large number of files and extensive data processing. As a result, execution may take a considerable amount of time. Please plan accordingly."
      ],
      "metadata": {
        "id": "a5ZY-jfrsm8w"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KKuBWqPqrz86",
        "outputId": "ea39008a-5713-429f-b099-272e61455847",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing file: /content/drive/MyDrive/MEG DATA/LSD_DRU_subject_15.mat\n",
            "Keys in the .mat file: ['#refs#', 'X', 'lnfilter']\n",
            "Processing file: /content/drive/MyDrive/MEG DATA/LSD_DRU_subject_14.mat\n",
            "Keys in the .mat file: ['#refs#', 'X', 'lnfilter']\n",
            "Processing file: /content/drive/MyDrive/MEG DATA/LSD_DRU_subject_13.mat\n",
            "Keys in the .mat file: ['#refs#', 'X', 'lnfilter']\n",
            "Processing file: /content/drive/MyDrive/MEG DATA/LSD_DRU_subject_12.mat\n",
            "Keys in the .mat file: ['#refs#', 'X', 'lnfilter']\n",
            "Processing file: /content/drive/MyDrive/MEG DATA/LSD_DRU_subject_11.mat\n",
            "Keys in the .mat file: ['#refs#', 'X', 'lnfilter']\n",
            "Processing file: /content/drive/MyDrive/MEG DATA/LSD_DRU_subject_09.mat\n",
            "Keys in the .mat file: ['#refs#', 'X', 'lnfilter']\n",
            "Processing file: /content/drive/MyDrive/MEG DATA/LSD_DRU_subject_10.mat\n",
            "Keys in the .mat file: ['#refs#', 'X', 'lnfilter']\n",
            "Processing file: /content/drive/MyDrive/MEG DATA/LSD_DRU_subject_08.mat\n",
            "Keys in the .mat file: ['#refs#', 'X', 'lnfilter']\n",
            "Processing file: /content/drive/MyDrive/MEG DATA/LSD_DRU_subject_05.mat\n",
            "Keys in the .mat file: ['#refs#', 'X', 'lnfilter']\n",
            "Processing file: /content/drive/MyDrive/MEG DATA/LSD_DRU_subject_07.mat\n",
            "Keys in the .mat file: ['#refs#', 'X', 'lnfilter']\n",
            "Processing file: /content/drive/MyDrive/MEG DATA/LSD_DRU_subject_04.mat\n",
            "Keys in the .mat file: ['#refs#', 'X', 'lnfilter']\n",
            "Processing file: /content/drive/MyDrive/MEG DATA/LSD_DRU_subject_06.mat\n",
            "Keys in the .mat file: ['#refs#', 'X', 'lnfilter']\n",
            "Processing file: /content/drive/MyDrive/MEG DATA/LSD_DRU_subject_01.mat\n",
            "Keys in the .mat file: ['#refs#', 'X', 'lnfilter']\n",
            "Processing file: /content/drive/MyDrive/MEG DATA/LSD_DRU_subject_02.mat\n",
            "Keys in the .mat file: ['#refs#', 'X', 'lnfilter']\n",
            "Processing file: /content/drive/MyDrive/MEG DATA/LSD_DRU_subject_03.mat\n",
            "Keys in the .mat file: ['#refs#', 'X', 'lnfilter']\n",
            "Processing file: /content/drive/MyDrive/MEG DATA/LSD_PLA_subject_03.mat\n",
            "Keys in the .mat file: ['#refs#', 'X', 'lnfilter']\n",
            "Processing file: /content/drive/MyDrive/MEG DATA/LSD_PLA_subject_01.mat\n",
            "Keys in the .mat file: ['#refs#', 'X', 'lnfilter']\n",
            "Processing file: /content/drive/MyDrive/MEG DATA/LSD_PLA_subject_02.mat\n",
            "Keys in the .mat file: ['#refs#', 'X', 'lnfilter']\n",
            "Processing file: /content/drive/MyDrive/MEG DATA/LSD_PLA_subject_06.mat\n",
            "Keys in the .mat file: ['#refs#', 'X', 'lnfilter']\n",
            "Processing file: /content/drive/MyDrive/MEG DATA/LSD_PLA_subject_04.mat\n",
            "Keys in the .mat file: ['#refs#', 'X', 'lnfilter']\n",
            "Processing file: /content/drive/MyDrive/MEG DATA/LSD_PLA_subject_07.mat\n",
            "Keys in the .mat file: ['#refs#', 'X', 'lnfilter']\n",
            "Processing file: /content/drive/MyDrive/MEG DATA/LSD_PLA_subject_05.mat\n",
            "Keys in the .mat file: ['#refs#', 'X', 'lnfilter']\n",
            "Processing file: /content/drive/MyDrive/MEG DATA/LSD_PLA_subject_09.mat\n",
            "Keys in the .mat file: ['#refs#', 'X', 'lnfilter']\n",
            "Processing file: /content/drive/MyDrive/MEG DATA/LSD_PLA_subject_08.mat\n",
            "Keys in the .mat file: ['#refs#', 'X', 'lnfilter']\n",
            "Processing file: /content/drive/MyDrive/MEG DATA/LSD_PLA_subject_10.mat\n",
            "Keys in the .mat file: ['#refs#', 'X', 'lnfilter']\n",
            "Processing file: /content/drive/MyDrive/MEG DATA/LSD_PLA_subject_11.mat\n",
            "Keys in the .mat file: ['#refs#', 'X', 'lnfilter']\n",
            "Processing file: /content/drive/MyDrive/MEG DATA/LSD_PLA_subject_12.mat\n",
            "Keys in the .mat file: ['#refs#', 'X', 'lnfilter']\n",
            "Processing file: /content/drive/MyDrive/MEG DATA/LSD_PLA_subject_13.mat\n",
            "Keys in the .mat file: ['#refs#', 'X', 'lnfilter']\n",
            "Processing file: /content/drive/MyDrive/MEG DATA/LSD_PLA_subject_14.mat\n",
            "Keys in the .mat file: ['#refs#', 'X', 'lnfilter']\n",
            "Processing file: /content/drive/MyDrive/MEG DATA/LSD_PLA_subject_15.mat\n",
            "Keys in the .mat file: ['#refs#', 'X', 'lnfilter']\n",
            "Processing file: /content/drive/MyDrive/MEG DATA/KET_DRU_subject_02.mat\n",
            "Keys in the .mat file: ['#refs#', 'X', 'lnfilter']\n",
            "Processing file: /content/drive/MyDrive/MEG DATA/KET_DRU_subject_03.mat\n",
            "Keys in the .mat file: ['#refs#', 'X', 'lnfilter']\n",
            "Processing file: /content/drive/MyDrive/MEG DATA/KET_DRU_subject_04.mat\n",
            "Keys in the .mat file: ['#refs#', 'X', 'lnfilter']\n",
            "Processing file: /content/drive/MyDrive/MEG DATA/KET_DRU_subject_05.mat\n",
            "Keys in the .mat file: ['#refs#', 'X', 'lnfilter']\n",
            "Processing file: /content/drive/MyDrive/MEG DATA/KET_DRU_subject_06.mat\n",
            "Keys in the .mat file: ['#refs#', 'X', 'lnfilter']\n",
            "Processing file: /content/drive/MyDrive/MEG DATA/KET_DRU_subject_08.mat\n",
            "Keys in the .mat file: ['#refs#', 'X', 'lnfilter']\n",
            "Processing file: /content/drive/MyDrive/MEG DATA/KET_DRU_subject_09.mat\n",
            "Keys in the .mat file: ['#refs#', 'X', 'lnfilter']\n",
            "Processing file: /content/drive/MyDrive/MEG DATA/KET_DRU_subject_10.mat\n",
            "Keys in the .mat file: ['#refs#', 'X', 'lnfilter']\n",
            "Processing file: /content/drive/MyDrive/MEG DATA/KET_DRU_subject_11.mat\n",
            "Keys in the .mat file: ['#refs#', 'X', 'lnfilter']\n",
            "Processing file: /content/drive/MyDrive/MEG DATA/KET_DRU_subject_13.mat\n",
            "Keys in the .mat file: ['#refs#', 'X', 'lnfilter']\n",
            "Processing file: /content/drive/MyDrive/MEG DATA/KET_DRU_subject_12.mat\n",
            "Keys in the .mat file: ['#refs#', 'X', 'lnfilter']\n",
            "Processing file: /content/drive/MyDrive/MEG DATA/KET_DRU_subject_15.mat\n",
            "Keys in the .mat file: ['#refs#', 'X', 'lnfilter']\n",
            "Processing file: /content/drive/MyDrive/MEG DATA/KET_DRU_subject_14.mat\n",
            "Keys in the .mat file: ['#refs#', 'X', 'lnfilter']\n",
            "Processing file: /content/drive/MyDrive/MEG DATA/KET_DRU_subject_17.mat\n",
            "Keys in the .mat file: ['#refs#', 'X', 'lnfilter']\n",
            "Processing file: /content/drive/MyDrive/MEG DATA/KET_DRU_subject_16.mat\n",
            "Keys in the .mat file: ['#refs#', 'X', 'lnfilter']\n",
            "Processing file: /content/drive/MyDrive/MEG DATA/KET_DRU_subject_18.mat\n",
            "Keys in the .mat file: ['#refs#', 'X', 'lnfilter']\n",
            "Processing file: /content/drive/MyDrive/MEG DATA/KET_DRU_subject_19.mat\n",
            "Keys in the .mat file: ['#refs#', 'X', 'lnfilter']\n",
            "Processing file: /content/drive/MyDrive/MEG DATA/KET_DRU_subject_01.mat\n",
            "Keys in the .mat file: ['#refs#', 'X', 'lnfilter']\n",
            "Processing file: /content/drive/MyDrive/MEG DATA/KET_DRU_subject_07.mat\n",
            "Keys in the .mat file: ['#refs#', 'X', 'lnfilter']\n",
            "Processing file: /content/drive/MyDrive/MEG DATA/KET_PLA_subject_01.mat\n",
            "Keys in the .mat file: ['#refs#', 'X', 'lnfilter']\n",
            "Processing file: /content/drive/MyDrive/MEG DATA/KET_PLA_subject_03.mat\n",
            "Keys in the .mat file: ['#refs#', 'X', 'lnfilter']\n",
            "Processing file: /content/drive/MyDrive/MEG DATA/KET_PLA_subject_02.mat\n",
            "Keys in the .mat file: ['#refs#', 'X', 'lnfilter']\n",
            "Processing file: /content/drive/MyDrive/MEG DATA/KET_PLA_subject_04.mat\n",
            "Keys in the .mat file: ['#refs#', 'X', 'lnfilter']\n",
            "Processing file: /content/drive/MyDrive/MEG DATA/KET_PLA_subject_05.mat\n",
            "Keys in the .mat file: ['#refs#', 'X', 'lnfilter']\n",
            "Processing file: /content/drive/MyDrive/MEG DATA/KET_PLA_subject_06.mat\n",
            "Keys in the .mat file: ['#refs#', 'X', 'lnfilter']\n",
            "Processing file: /content/drive/MyDrive/MEG DATA/KET_PLA_subject_07.mat\n",
            "Keys in the .mat file: ['#refs#', 'X', 'lnfilter']\n",
            "Processing file: /content/drive/MyDrive/MEG DATA/KET_PLA_subject_08.mat\n",
            "Keys in the .mat file: ['#refs#', 'X', 'lnfilter']\n",
            "Processing file: /content/drive/MyDrive/MEG DATA/KET_PLA_subject_09.mat\n",
            "Keys in the .mat file: ['#refs#', 'X', 'lnfilter']\n",
            "Processing file: /content/drive/MyDrive/MEG DATA/KET_PLA_subject_11.mat\n",
            "Keys in the .mat file: ['#refs#', 'X', 'lnfilter']\n",
            "Processing file: /content/drive/MyDrive/MEG DATA/KET_PLA_subject_10.mat\n",
            "Keys in the .mat file: ['#refs#', 'X', 'lnfilter']\n",
            "Processing file: /content/drive/MyDrive/MEG DATA/KET_PLA_subject_12.mat\n",
            "Keys in the .mat file: ['#refs#', 'X', 'lnfilter']\n",
            "Processing file: /content/drive/MyDrive/MEG DATA/KET_PLA_subject_14.mat\n",
            "Keys in the .mat file: ['#refs#', 'X', 'lnfilter']\n",
            "Processing file: /content/drive/MyDrive/MEG DATA/KET_PLA_subject_13.mat\n",
            "Keys in the .mat file: ['#refs#', 'X', 'lnfilter']\n",
            "Processing file: /content/drive/MyDrive/MEG DATA/KET_PLA_subject_15.mat\n",
            "Keys in the .mat file: ['#refs#', 'X', 'lnfilter']\n",
            "Processing file: /content/drive/MyDrive/MEG DATA/KET_PLA_subject_16.mat\n",
            "Keys in the .mat file: ['#refs#', 'X', 'lnfilter']\n",
            "Processing file: /content/drive/MyDrive/MEG DATA/KET_PLA_subject_17.mat\n",
            "Keys in the .mat file: ['#refs#', 'X', 'lnfilter']\n",
            "Processing file: /content/drive/MyDrive/MEG DATA/KET_PLA_subject_19.mat\n",
            "Keys in the .mat file: ['#refs#', 'X', 'lnfilter']\n",
            "Processing file: /content/drive/MyDrive/MEG DATA/KET_PLA_subject_18.mat\n",
            "Keys in the .mat file: ['#refs#', 'X', 'lnfilter']\n",
            "Processing file: /content/drive/MyDrive/MEG DATA/PSI_DRU_subject_03.mat\n",
            "Keys in the .mat file: ['#refs#', 'X', 'lnfilter']\n",
            "Processing file: /content/drive/MyDrive/MEG DATA/PSI_DRU_subject_02.mat\n",
            "Keys in the .mat file: ['#refs#', 'X', 'lnfilter']\n",
            "Processing file: /content/drive/MyDrive/MEG DATA/PSI_DRU_subject_04.mat\n",
            "Keys in the .mat file: ['#refs#', 'X', 'lnfilter']\n",
            "Processing file: /content/drive/MyDrive/MEG DATA/PSI_DRU_subject_01.mat\n",
            "Keys in the .mat file: ['#refs#', 'X', 'lnfilter']\n",
            "Processing file: /content/drive/MyDrive/MEG DATA/PSI_DRU_subject_05.mat\n",
            "Keys in the .mat file: ['#refs#', 'X', 'lnfilter']\n",
            "Processing file: /content/drive/MyDrive/MEG DATA/PSI_DRU_subject_08.mat\n",
            "Keys in the .mat file: ['#refs#', 'X', 'lnfilter']\n",
            "Processing file: /content/drive/MyDrive/MEG DATA/PSI_DRU_subject_06.mat\n",
            "Keys in the .mat file: ['#refs#', 'X', 'lnfilter']\n",
            "Processing file: /content/drive/MyDrive/MEG DATA/PSI_DRU_subject_07.mat\n",
            "Keys in the .mat file: ['#refs#', 'X', 'lnfilter']\n",
            "Processing file: /content/drive/MyDrive/MEG DATA/PSI_DRU_subject_09.mat\n",
            "Keys in the .mat file: ['#refs#', 'X', 'lnfilter']\n",
            "Processing file: /content/drive/MyDrive/MEG DATA/PSI_DRU_subject_10.mat\n",
            "Keys in the .mat file: ['#refs#', 'X', 'lnfilter']\n",
            "Processing file: /content/drive/MyDrive/MEG DATA/PSI_DRU_subject_12.mat\n",
            "Keys in the .mat file: ['#refs#', 'X', 'lnfilter']\n",
            "Processing file: /content/drive/MyDrive/MEG DATA/PSI_DRU_subject_11.mat\n",
            "Keys in the .mat file: ['#refs#', 'X', 'lnfilter']\n",
            "Processing file: /content/drive/MyDrive/MEG DATA/PSI_DRU_subject_13.mat\n",
            "Keys in the .mat file: ['#refs#', 'X', 'lnfilter']\n",
            "Processing file: /content/drive/MyDrive/MEG DATA/PSI_DRU_subject_14.mat\n",
            "Keys in the .mat file: ['#refs#', 'X', 'lnfilter']\n",
            "Processing file: /content/drive/MyDrive/MEG DATA/PSI_PLA_subject_02.mat\n",
            "Keys in the .mat file: ['#refs#', 'X', 'lnfilter']\n",
            "Processing file: /content/drive/MyDrive/MEG DATA/PSI_PLA_subject_01.mat\n",
            "Keys in the .mat file: ['#refs#', 'X', 'lnfilter']\n",
            "Processing file: /content/drive/MyDrive/MEG DATA/PSI_PLA_subject_06.mat\n",
            "Keys in the .mat file: ['#refs#', 'X', 'lnfilter']\n",
            "Processing file: /content/drive/MyDrive/MEG DATA/PSI_PLA_subject_07.mat\n",
            "Keys in the .mat file: ['#refs#', 'X', 'lnfilter']\n",
            "Processing file: /content/drive/MyDrive/MEG DATA/PSI_PLA_subject_04.mat\n",
            "Keys in the .mat file: ['#refs#', 'X', 'lnfilter']\n",
            "Processing file: /content/drive/MyDrive/MEG DATA/PSI_PLA_subject_05.mat\n",
            "Keys in the .mat file: ['#refs#', 'X', 'lnfilter']\n",
            "Processing file: /content/drive/MyDrive/MEG DATA/PSI_PLA_subject_03.mat\n",
            "Keys in the .mat file: ['#refs#', 'X', 'lnfilter']\n",
            "Processing file: /content/drive/MyDrive/MEG DATA/PSI_PLA_subject_10.mat\n",
            "Keys in the .mat file: ['#refs#', 'X', 'lnfilter']\n",
            "Processing file: /content/drive/MyDrive/MEG DATA/PSI_PLA_subject_08.mat\n",
            "Keys in the .mat file: ['#refs#', 'X', 'lnfilter']\n",
            "Processing file: /content/drive/MyDrive/MEG DATA/PSI_PLA_subject_09.mat\n",
            "Keys in the .mat file: ['#refs#', 'X', 'lnfilter']\n",
            "Processing file: /content/drive/MyDrive/MEG DATA/PSI_PLA_subject_11.mat\n",
            "Keys in the .mat file: ['#refs#', 'X', 'lnfilter']\n",
            "Processing file: /content/drive/MyDrive/MEG DATA/PSI_PLA_subject_14.mat\n",
            "Keys in the .mat file: ['#refs#', 'X', 'lnfilter']\n",
            "Processing file: /content/drive/MyDrive/MEG DATA/PSI_PLA_subject_13.mat\n",
            "Keys in the .mat file: ['#refs#', 'X', 'lnfilter']\n",
            "Processing file: /content/drive/MyDrive/MEG DATA/PSI_PLA_subject_12.mat\n",
            "Keys in the .mat file: ['#refs#', 'X', 'lnfilter']\n",
            "  Psychedelic Condition  Subject  Channel           ROI  LZ Complexity\n",
            "0         LSD       DRU       15        2  sensorimotor       0.849591\n",
            "1         LSD       DRU       15       57  sensorimotor       0.808038\n",
            "2         LSD       DRU       15       58  sensorimotor       0.766071\n",
            "3         LSD       DRU       15        6       frontal       0.793884\n",
            "4         LSD       DRU       15       23       frontal       0.856824\n"
          ]
        }
      ],
      "source": [
        "# Define ROIs and their corresponding regions\n",
        "roi_regions = {\n",
        "    'sensorimotor': [1, 2, 17, 18, 57, 58],\n",
        "    'frontal': [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28],\n",
        "    'temporal': [29, 30, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90],\n",
        "    'cingulate': [31, 32, 33, 34, 35, 36],\n",
        "    'limbic': [37, 38, 39, 40, 41, 42],\n",
        "    'occipital': [43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56],\n",
        "    'parietal': [59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70],\n",
        "    'subcortical': [71, 72, 73, 74, 75, 76, 77, 78]\n",
        "}\n",
        "\n",
        "# Function to randomly select channels from each ROI\n",
        "def select_random_rois(roi_regions, num_samples_per_region=3):\n",
        "    selected_rois = []\n",
        "    roi_names = []\n",
        "    for region, rois in roi_regions.items():\n",
        "        sampled_rois = random.sample(rois, num_samples_per_region)\n",
        "        selected_rois.extend(sampled_rois)\n",
        "        roi_names.extend([region] * num_samples_per_region)\n",
        "    return selected_rois, roi_names\n",
        "\n",
        "# Function to apply a bandpass filter to the data\n",
        "def apply_bandpass_filter(data, low_cutoff, high_cutoff, fs):\n",
        "    nyq = 0.5 * fs\n",
        "    low = low_cutoff / nyq\n",
        "    high = high_cutoff / nyq\n",
        "    b, a = butter(4, [low, high], btype='band')\n",
        "    filtered_data = np.zeros_like(data)\n",
        "    for i in range(data.shape[1]):\n",
        "        filtered_data[:, i] = filtfilt(b, a, data[:, i])\n",
        "    return filtered_data\n",
        "\n",
        "# Function to detrend and preprocess the data\n",
        "def Pre(X):\n",
        "    epochs, ro = X.shape\n",
        "    Z = np.zeros((epochs, ro))\n",
        "    for e in range(epochs):\n",
        "        Z[e, :] = detrend(X[e, :] - np.mean(X[e, :]), axis=0)\n",
        "    return Z\n",
        "\n",
        "# Function to detrend and preprocess the data\n",
        "def cpr(string):\n",
        "    d = {}\n",
        "    w = ''\n",
        "    for c in string:\n",
        "        wc = w + c\n",
        "        if wc in d:\n",
        "            w = wc\n",
        "        else:\n",
        "            d[wc] = wc\n",
        "            w = c\n",
        "    return len(d)\n",
        "\n",
        "# Function to convert data into a binary string representation\n",
        "def str_col(X):\n",
        "    epochs, ro = X.shape\n",
        "    TH = np.zeros(epochs)\n",
        "    M = np.zeros((epochs, ro))\n",
        "    for e in range(epochs):\n",
        "        M[e, :] = np.abs(hilbert(X[e, :]))\n",
        "        TH[e] = np.mean(M[e, :])\n",
        "\n",
        "    s = ''\n",
        "    for e in range(epochs):\n",
        "        for i in range(ro):\n",
        "            if M[e, i] > TH[e]:\n",
        "                s += '1'\n",
        "            else:\n",
        "                s += '0'\n",
        "    return s\n",
        "\n",
        "\n",
        "\n",
        "# Function to compute the Lempel-Ziv complexity\n",
        "def LZc(X):\n",
        "    X = Pre(X)\n",
        "    SC = str_col(X)\n",
        "    M = list(SC)\n",
        "    random.shuffle(M)\n",
        "    w = ''\n",
        "    for i in range(len(M)):\n",
        "        w += M[i]\n",
        "    return cpr(SC) / float(cpr(w))\n",
        "\n",
        "# Function to load .mat files using h5py\n",
        "def load_mat_file_h5py(mat_file_path):\n",
        "    try:\n",
        "        with h5py.File(mat_file_path, 'r') as f:\n",
        "            print(\"Keys in the .mat file:\", list(f.keys()))\n",
        "            data = f['X'][:]  # Replace 'X' with the actual key for your data\n",
        "            return data\n",
        "    except (OSError, KeyError) as e:\n",
        "        print(f\"Error loading file {mat_file_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "# Function to process a .mat file, including data filtering, LZ complexity calculation, and averaging results\n",
        "def process_file(mat_file_path, num_iterations=30):\n",
        "    # Load the data\n",
        "    data = load_mat_file_h5py(mat_file_path)\n",
        "    if data is None:\n",
        "        return []\n",
        "\n",
        "    results = []\n",
        "\n",
        "    for _ in range(num_iterations):\n",
        "        # Sample random ROIs and get their names (brain region)\n",
        "        sampled_rois, roi_names = select_random_rois(roi_regions, num_samples_per_region=3)\n",
        "\n",
        "        for i, roi in enumerate(sampled_rois):\n",
        "            try:\n",
        "                # Extract the data for the current ROI\n",
        "                selected_data = data[:, roi, :]\n",
        "\n",
        "                # Perform downsampling to 200Hz\n",
        "                decimation_factor = 3\n",
        "                downsampled_data = selected_data[:, ::decimation_factor]\n",
        "\n",
        "                # Apply bandpass filter\n",
        "                filtered_data = apply_bandpass_filter(downsampled_data, low_cutoff=0.1, high_cutoff=30, fs=600)\n",
        "\n",
        "                # Compute LZ complexity\n",
        "                lz_complexity = LZc(filtered_data)\n",
        "\n",
        "                # Append the result\n",
        "                results.append((roi, roi_names[i], lz_complexity))\n",
        "            except Exception as e:\n",
        "                print(f\"Failed to process ROI {roi} in file {mat_file_path} due to error: {e}\")\n",
        "\n",
        "    # Calculate the average LZ complexity for each ROI\n",
        "    averaged_results = {}\n",
        "    for roi, roi_name, lz_complexity in results:\n",
        "        if (roi, roi_name) not in averaged_results:\n",
        "            averaged_results[(roi, roi_name)] = []\n",
        "        averaged_results[(roi, roi_name)].append(lz_complexity)\n",
        "\n",
        "    final_results = []\n",
        "    for (roi, roi_name), complexities in averaged_results.items():\n",
        "        avg_complexity = np.mean(complexities)\n",
        "        final_results.append((roi, roi_name, avg_complexity))\n",
        "\n",
        "    return final_results\n",
        "\n",
        "# Function to extract the subject number from the file path\n",
        "def extract_subject_number(file_path):\n",
        "    base_name = os.path.basename(file_path)\n",
        "    match = re.search(r'subject_(\\d+)', base_name)\n",
        "    if match:\n",
        "        return int(match.group(1))\n",
        "    return None\n",
        "\n",
        "# Main function to collect data across different conditions and psychedelics\n",
        "def collect_data(base_path, psychedelics, conditions, num_iterations=30):\n",
        "    all_results = []\n",
        "    error_files = []\n",
        "\n",
        "    for psychedelic in psychedelics:\n",
        "        for condition in conditions:\n",
        "            file_pattern = f\"{base_path}/{psychedelic}_{condition}_subject_*.mat\"\n",
        "            file_paths = glob.glob(file_pattern)\n",
        "\n",
        "            for file_path in file_paths:\n",
        "                print(f\"Processing file: {file_path}\")\n",
        "                try:\n",
        "                    subject_number = extract_subject_number(file_path)\n",
        "                    lz_complexities = process_file(file_path, num_iterations)\n",
        "\n",
        "                    for roi, roi_name, lz_complexity in lz_complexities:\n",
        "                        all_results.append({\n",
        "                            'Psychedelic': psychedelic,\n",
        "                            'Condition': condition,\n",
        "                            'Subject': subject_number,\n",
        "                            'Channel': roi,\n",
        "                            'ROI': roi_name,\n",
        "                            'LZ Complexity': lz_complexity\n",
        "                        })\n",
        "                except Exception as e:\n",
        "                    print(f\"Failed to process file {file_path} due to error: {e}\")\n",
        "                    error_files.append(file_path)\n",
        "\n",
        "    if error_files:\n",
        "        print(\"Files that caused errors:\")\n",
        "        for error_file in error_files:\n",
        "            print(error_file)\n",
        "\n",
        "    return pd.DataFrame(all_results)\n",
        "\n",
        "# Define parameters\n",
        "base_path = '/content/drive/MyDrive/MEG DATA'\n",
        "psychedelics = ['LSD', 'KET', 'PSI']\n",
        "conditions = ['DRU', 'PLA']\n",
        "\n",
        "# Collect the data into a dataframe\n",
        "LZ_df = collect_data(base_path, psychedelics, conditions, num_iterations=10)\n",
        "\n",
        "# Save results to CSV\n",
        "LZ_df.to_csv('lz_complexities.csv', index=False)\n",
        "\n",
        "# Print the first few rows of results_df\n",
        "print(LZ_df.head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ONCE RESULTS HAVE BEEN SAVED TO CSV, PLEASE PROCEED TO THE 'PRIMARY ANALYSIS & ML PIPELINE JUPYTER' NOTEBOOK.  \n"
      ],
      "metadata": {
        "id": "8Nw16ttsW1Mm"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AUO2QNeLwK_o"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}